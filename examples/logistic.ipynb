{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NP4VTT: Logistic regression\n",
    "\n",
    "In this notebook, we show how to use a logistic regression model to estimate the distribution of the Value of Travel Time (VTT) from the Norway data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load modules and data, and create arrays\n",
    "\n",
    "We first import the NP4VTT modules for creating the arrays, the logistic regression model, and Pandas to load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from py_np4vtt.data_format import StudyVar\n",
    "from py_np4vtt.model_logistic import ModelLogistic, ConfigLogistic\n",
    "from py_np4vtt.data_import import make_modelarrays, compute_descriptives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read the CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RespID</th>\n",
       "      <th>Mode</th>\n",
       "      <th>TravTime</th>\n",
       "      <th>BaseCost</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AgeClass</th>\n",
       "      <th>IncClass</th>\n",
       "      <th>TravTimeClass</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>CardID</th>\n",
       "      <th>...</th>\n",
       "      <th>TimeL</th>\n",
       "      <th>TimeR</th>\n",
       "      <th>Chosen</th>\n",
       "      <th>Quadrant2</th>\n",
       "      <th>Purpose2</th>\n",
       "      <th>Mode2</th>\n",
       "      <th>Income2</th>\n",
       "      <th>ExclGroup</th>\n",
       "      <th>Exclude_CDF</th>\n",
       "      <th>CS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RespID  Mode  TravTime  BaseCost  Gender  AgeClass  IncClass  \\\n",
       "0      88     1        25        27       1         3         5   \n",
       "1      88     1        25        27       1         3         5   \n",
       "2      88     1        25        27       1         3         5   \n",
       "3      88     1        25        27       1         3         5   \n",
       "4      88     1        25        27       1         3         5   \n",
       "\n",
       "   TravTimeClass  Purpose  CardID  ...  TimeL  TimeR  Chosen  Quadrant2  \\\n",
       "0              1        1       1  ...     32     25       1          4   \n",
       "1              1        1       2  ...     25     28       2          2   \n",
       "2              1        1       3  ...     29     25       1          4   \n",
       "3              1        1       4  ...     32     25       1          2   \n",
       "4              1        1       5  ...     29     32       2          2   \n",
       "\n",
       "   Purpose2  Mode2  Income2  ExclGroup  Exclude_CDF  CS  \n",
       "0         1      1        3          4            1   1  \n",
       "1         1      1        3          4            1   2  \n",
       "2         1      1        3          4            1   3  \n",
       "3         1      1        3          4            1   4  \n",
       "4         1      1        3          4            1   5  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('../data/Norway09_data_v5.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 22 variables. Each row is a binary choice task. We will use:\n",
    "\n",
    "* `RespID`: ID of each respondent.\n",
    "* `Chosen`: Chosen alternative.\n",
    "* `CostL`: Travel cost of alternatives 1 [NOK]\n",
    "* `CostR`: Travel cost of alternatives 2 [NOK]\n",
    "* `TimeL`: Travel time of alternatives 1 [minutes]\n",
    "* `TimeR`: Travel time of alternatives 2 [minutes]\n",
    "\n",
    "NP4VTT detects automatically the _slow and cheap_ and _fast and expensive_ alternative, for each choice situation. If NP4VTT finds violations to those two options (e.g., a fast-cheap) alternative, it will raise an error message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change currency of travel time to euros and change unit of travel time to hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to euros\n",
    "NOK2euro_exchange_rate = 9\n",
    "df[['CostL','CostR']] = df[['CostL','CostR']] .div(NOK2euro_exchange_rate)\n",
    "\n",
    "# convert to hours\n",
    "df[['TimeL','TimeR']] = df[['TimeL','TimeR']] .div(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a dictionary to map the required variables for NP4VTT with the variables of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnarrays = {\n",
    "    StudyVar.Id: 'RespID',\n",
    "    StudyVar.ChosenAlt: 'Chosen',\n",
    "    StudyVar.Cost1: 'CostL',\n",
    "    StudyVar.Cost2: 'CostR',\n",
    "    StudyVar.Time1: 'TimeL',\n",
    "    StudyVar.Time2: 'TimeR',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we create the required arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arrays = make_modelarrays(df, columnarrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `make_modelarrays` creates six elements used by NP4VTT to estimate/train a model:\n",
    "\n",
    "* `BVTT`: Contains the Boundary VTT per choice situation, computed from costs and time.\n",
    "* `Choice`: A matrix of dummy variables that are equal to one if the respondent choose the fast-expensive alternative on each choice situation.\n",
    "* `Accepts`: Number of times a respondent chose the fast-expensive alternative.\n",
    "* `ID`: Unique identifier of each respondent.\n",
    "* `NP`: Number of respondents in the dataset.\n",
    "* `T`: Number of choice situations per respondent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Compute descriptives\n",
    "\n",
    "The function `compute_descriptives` provides a small overview of the dataset characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. individuals: 5832\n",
      "Sets per indiv.: 9\n",
      "\n",
      "Number of non-traders:\n",
      "Fast-exp. alt.: 144\n",
      "Slow-cheap alt.: 808\n",
      "\n",
      "BVTT statistics:\n",
      "Mean chosen BVTT: 3.5800867802855794\n",
      "Minimum of BVTT: 0.6666666666666644\n",
      "Maximum of BVTT: 113.56321839080461\n"
     ]
    }
   ],
   "source": [
    "descriptives = compute_descriptives(model_arrays)\n",
    "print(descriptives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure a logistic regression model\n",
    "\n",
    "The logistic regression model requires the following parameters from the user:\n",
    "\n",
    "* `mleIntercept`: The starting value of the intercept parameter\n",
    "* `mleParameter`: The starting value of the VTT parameter.\n",
    "* `mleScale`: The starting value of the scale parameter.\n",
    "\n",
    "Additionally, the user can configure the following options:\n",
    "* `mleMaxIterations:` Maximum iterations of the maximum likelihood estimation routine.\n",
    "* `seed`: Random seed for the array creation in the logistic regression model.\n",
    "\n",
    "The function `ConfigLogistic` takes the configuration parameters of the logistic regression and creates an object that is used by the optimisation routine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigLogistic(mleIntercept=0, mleParameter=10, mleScale=0.1, mleMaxIterations=10000, seed=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create the logistic regression model object that contains the configuration parameters and the data arrays. Then, we initialise the arguments and the initial value of the likelihood function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = ModelLogistic(config, model_arrays)\n",
    "initialArgs, initialVal = logistic.setupInitialArgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Estimate a logistic regression model\n",
    "\n",
    "Once the logistic regression is initialised, the `run` method starts the optimisation process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src\\py_np4vtt\\model_logistic.py:114: RuntimeWarning: divide by zero encountered in log\n",
      "  ll = - np.sum(np.log(p * (y_regress == 0) + (1 - p) * (y_regress == 1)))\n",
      "C:\\Users\\sandervancranenburgh\\AppData\\Roaming\\Python\\Python38\\site-packages\\scipy\\optimize\\_numdiff.py:557: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n",
      "../src\\py_np4vtt\\model_logistic.py:113: RuntimeWarning: overflow encountered in exp\n",
      "  p = np.exp(V1) / (np.exp(V1) + np.exp(V2))\n",
      "../src\\py_np4vtt\\model_logistic.py:93: RuntimeWarning: invalid value encountered in sqrt\n",
      "  se = np.sqrt(np.diag(np.linalg.inv(hess)))\n"
     ]
    }
   ],
   "source": [
    "x, se, fval, exitflag, output = logistic.run(initialArgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated model returns the following information:\n",
    "\n",
    "* `x:` The estimated parameters for the intercept, the VTT parameter, and the scale.\n",
    "* `se:` The standard error of the estimated parameters.\n",
    "* `fval:` Value of the likelihood function in the optimum.\n",
    "* `exitflag:` Exit flag of the optimisation routine.\n",
    "* `output:` output message of the optimisation routine.\n",
    "\n",
    "The following lines present the estimated results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation results:\n",
      "\n",
      "Initial log-likelihood: -60639.36\n",
      "Final log-likelihood: -60639.36\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SANDER~1\\AppData\\Local\\Temp/ipykernel_14784/440705940.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Initial log-likelihood: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitialVal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Final log-likelihood: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Estimates:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create dataframe\n",
    "results = pd.DataFrame(np.c_[x,se],columns=['Estimate','Std.Err'],index=['Scale','Intercept','Parameter'])\n",
    "\n",
    "print('Estimation results:\\n')\n",
    "print('Initial log-likelihood: ' + str(round(initialVal,2)))\n",
    "print('Final log-likelihood: ' + str(round(fval,2)))\n",
    "print(output + '\\n')\n",
    "print('Estimates:')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VTT for each respondent can be computed from the estimated parameters and the model arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = model_arrays.T\n",
    "NP = model_arrays.NP\n",
    "BVTT = model_arrays.BVTT\n",
    "Choice = model_arrays.Choice\n",
    "\n",
    "VTT = x[1] + x[2]*((T-1)/T)*np.sum(Choice*BVTT,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visualising the VTT distribution\n",
    "\n",
    "We create the empirical Cumulative Density Function plot of the VTT distribution. For easy interpretation, we use create a histogram from the CDF. \n",
    "We use matplotlib for this:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
